{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c65d4f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparation of dataset using GenZDealZ.ai platform, all the plotforms mention are from GenZDealZ.ai\n",
    "platforms = ['AMAZON PRIME Membership','Flipkart','Amazon Shopping','Zomato','Myntra','Hotstar','McDonald', \n",
    "'Pizza Hut','OLA Cabs'\n",
    "'PVR Cinemas',\n",
    "'Reliance Digital',\n",
    "'KFC',\n",
    "'MakeMyTrip',\n",
    "'Uber',\n",
    "'Cafe Coffee Day',\n",
    "'Blinkit',\n",
    "'Swiggy',\n",
    "'AJIO','Vijay Sales',\n",
    "'Croma',\n",
    "'Dominos',\n",
    "'Wildcraft',\n",
    "'Reliance Smart',\n",
    "'Max Fashion',\n",
    "'Netmeds',\n",
    "'Puma',\n",
    "'Westside',\n",
    "'Fastrack',\n",
    "'Nykaa',\n",
    "'Bewakoof',\n",
    "'Zee5',\n",
    "'Gaana',\n",
    "'Louis Philippe',\n",
    "'@Home (Processing)',\n",
    "'1mg Prescription Medicine',\n",
    "'Abhibus',\n",
    "'Absolute Barbecue',\n",
    "'AD','Aeropostale','Aldo','Aligarh House by Eatfit','Allen Solly','ALT BALAJI','Amazon Kindle Unlimited','American Eagle','AND India','Anita Dongre','Apollo Pharmacy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06d96772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AMAZON PRIME Membership',\n",
       " 'Flipkart',\n",
       " 'Amazon Shopping',\n",
       " 'Zomato',\n",
       " 'Myntra',\n",
       " 'Hotstar',\n",
       " 'McDonald',\n",
       " 'Pizza Hut',\n",
       " 'OLA CabsPVR Cinemas',\n",
       " 'Reliance Digital',\n",
       " 'KFC',\n",
       " 'MakeMyTrip',\n",
       " 'Uber',\n",
       " 'Cafe Coffee Day',\n",
       " 'Blinkit',\n",
       " 'Swiggy',\n",
       " 'AJIO',\n",
       " 'Vijay Sales',\n",
       " 'Croma',\n",
       " 'Dominos',\n",
       " 'Wildcraft',\n",
       " 'Reliance Smart',\n",
       " 'Max Fashion',\n",
       " 'Netmeds',\n",
       " 'Puma',\n",
       " 'Westside',\n",
       " 'Fastrack',\n",
       " 'Nykaa',\n",
       " 'Bewakoof',\n",
       " 'Zee5',\n",
       " 'Gaana',\n",
       " 'Louis Philippe',\n",
       " '@Home (Processing)',\n",
       " '1mg Prescription Medicine',\n",
       " 'Abhibus',\n",
       " 'Absolute Barbecue',\n",
       " 'AD',\n",
       " 'Aeropostale',\n",
       " 'Aldo',\n",
       " 'Aligarh House by Eatfit',\n",
       " 'Allen Solly',\n",
       " 'ALT BALAJI',\n",
       " 'Amazon Kindle Unlimited',\n",
       " 'American Eagle',\n",
       " 'AND India',\n",
       " 'Anita Dongre',\n",
       " 'Apollo Pharmacy']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "platforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6de0f4",
   "metadata": {},
   "source": [
    "Dataset Preparation according to the given Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "913a9879",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Function to generate a random sequence of purchases\n",
    "def generate_purchases(num_purchases):\n",
    "    return random.sample(platforms, num_purchases)\n",
    "\n",
    "# Function to create the dataset\n",
    "def create_dataset(num_users):\n",
    "    data = []\n",
    "    for i in range(1, num_users + 1):\n",
    "        user_id = f'user{i}'\n",
    "        num_purchases = random.randint(1, len(platforms))  # Random number of purchases\n",
    "        purchases = generate_purchases(num_purchases)\n",
    "        data.append({'user': user_id, 'purchases': purchases})\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d38e040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a dataset with 50000 users\n",
    "dataset = create_dataset(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20618f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Flipkart',\n",
       " 'AND India',\n",
       " 'Fastrack',\n",
       " 'Nykaa',\n",
       " 'Dominos',\n",
       " 'Netmeds',\n",
       " 'Aldo',\n",
       " 'Amazon Shopping',\n",
       " 'Pizza Hut',\n",
       " 'Aligarh House by Eatfit',\n",
       " '@Home (Processing)',\n",
       " 'ALT BALAJI',\n",
       " 'Reliance Digital',\n",
       " 'American Eagle',\n",
       " 'Zee5',\n",
       " 'AJIO',\n",
       " 'Westside',\n",
       " 'Apollo Pharmacy',\n",
       " 'Vijay Sales',\n",
       " 'AD']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]['purchases']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7897450c",
   "metadata": {},
   "source": [
    "Pre Processing Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "527de189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Encoding dataset\n",
    "all_purchases = [purchase for entry in dataset for purchase in entry['purchases']]\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(all_purchases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "826ddbbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1196213"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_purchases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c63d29ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert purchases to numerical data\n",
    "def encode_purchases(purchases):\n",
    "    return label_encoder.transform(purchases)\n",
    "\n",
    "# Function to prepare input-output pairs for the model\n",
    "def create_input_output_pairs(data):\n",
    "    X, y = [], []\n",
    "    for entry in data:\n",
    "        purchases = encode_purchases(entry['purchases'])\n",
    "        X.append(purchases[:-1])   # Input sequence\n",
    "        y.append(purchases[-1])    # Output sequence(last purchase)\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2586c1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_input_output_pairs(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b647dc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Pad sequences to ensure uniform length\n",
    "max_length = max(len(seq) for seq in X)\n",
    "X = pad_sequences(X, maxlen=max_length, padding='post')\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d622f039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X[990]) # It ensures length of every seuence is equal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcca6192",
   "metadata": {},
   "source": [
    "Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0dab6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "211aa478",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train, num_classes=len(label_encoder.classes_))\n",
    "y_test = to_categorical(y_test, num_classes=len(label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7826e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 46, 100)           4700      \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 46, 128)           117248    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 5888)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               1507584   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 47)                12079     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,641,611\n",
      "Trainable params: 1,641,611\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, Masking, LSTM, Flatten\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=len(label_encoder.classes_), output_dim=100, input_length=max_length),\n",
    "    LSTM(128, return_sequences=True),  # LSTM layer with return_sequences=True to pass sequences to dense layers\n",
    "    Flatten(),  # Flatten the output of LSTM layer\n",
    "    Dense(256, activation='relu'),  # Add a dense layer with ReLU activation\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy',  # Use categorical crossentropy for one-hot encoded labels\n",
    "              metrics=['accuracy', Precision(), Recall()])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "900fe6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "500/500 [==============================] - 34s 66ms/step - loss: 3.8343 - accuracy: 0.0290 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 3.8197 - val_accuracy: 0.0361 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 34s 68ms/step - loss: 3.6608 - accuracy: 0.0633 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 3.7058 - val_accuracy: 0.0499 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 33s 67ms/step - loss: 3.2869 - accuracy: 0.1367 - precision: 0.6616 - recall: 0.0137 - val_loss: 3.7279 - val_accuracy: 0.0510 - val_precision: 0.2231 - val_recall: 0.0036\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 33s 66ms/step - loss: 2.7830 - accuracy: 0.2561 - precision: 0.7953 - recall: 0.1052 - val_loss: 3.9787 - val_accuracy: 0.0545 - val_precision: 0.1389 - val_recall: 0.0114\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 34s 67ms/step - loss: 2.2332 - accuracy: 0.4027 - precision: 0.8924 - recall: 0.2567 - val_loss: 4.4446 - val_accuracy: 0.0484 - val_precision: 0.1040 - val_recall: 0.0190\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 32s 64ms/step - loss: 1.7632 - accuracy: 0.5320 - precision: 0.9357 - recall: 0.4012 - val_loss: 5.1422 - val_accuracy: 0.0480 - val_precision: 0.0830 - val_recall: 0.0230\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 33s 66ms/step - loss: 1.4012 - accuracy: 0.6339 - precision: 0.9591 - recall: 0.5187 - val_loss: 6.0615 - val_accuracy: 0.0463 - val_precision: 0.0665 - val_recall: 0.0259\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 33s 66ms/step - loss: 1.1356 - accuracy: 0.7062 - precision: 0.9707 - recall: 0.6081 - val_loss: 6.7642 - val_accuracy: 0.0499 - val_precision: 0.0652 - val_recall: 0.0292\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 33s 66ms/step - loss: 0.9557 - accuracy: 0.7557 - precision: 0.9729 - recall: 0.6699 - val_loss: 7.5930 - val_accuracy: 0.0471 - val_precision: 0.0627 - val_recall: 0.0319\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 138s 277ms/step - loss: 0.8370 - accuracy: 0.7891 - precision: 0.9717 - recall: 0.7113 - val_loss: 8.1180 - val_accuracy: 0.0470 - val_precision: 0.0605 - val_recall: 0.0325\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91c2b1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 9ms/step - loss: 8.1814 - accuracy: 0.0478 - precision: 0.0618 - recall: 0.0336\n",
      "Loss: 8.18142032623291, Accuracy: 0.04780000075697899, Precision: 0.06175335496664047, Recall: 0.03359999880194664\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "loss, accuracy, precision, recall = model.evaluate(X_test, y_test)\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2934f6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 303ms/step\n",
      "Predicted next purchase: Aligarh House by Eatfit\n"
     ]
    }
   ],
   "source": [
    "# Test the model with a single example\n",
    "test_sequence = X_test[0]  # Select the first test sequence for demonstration\n",
    "test_sequence = np.expand_dims(test_sequence, axis=0)  # Model expects 3D input (batch_size, sequence_length, num_features)\n",
    "predicted_probabilities = model.predict(test_sequence)\n",
    "predicted_class = np.argmax(predicted_probabilities, axis=-1)  # Get the class with the highest probability\n",
    "predicted_platform = label_encoder.inverse_transform(predicted_class)\n",
    "print(f\"Predicted next purchase: {predicted_platform[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f7c707c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual next purchase: Zee5\n"
     ]
    }
   ],
   "source": [
    "# The actual next purchase in the test set\n",
    "actual_next_purchase = label_encoder.inverse_transform([np.argmax(y_test[0])])\n",
    "print(f\"Actual next purchase: {actual_next_purchase[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3398b35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
